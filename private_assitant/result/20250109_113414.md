
**You:** # private_assistant_v2.py
# -*- coding: utf-8 -*-
import os
import logging
import time

from langchain.agents import Tool
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI

from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from google.api_core.exceptions import ResourceExhausted

# 配置日志记录
logging.basicConfig(level=logging.INFO)
logging.getLogger("httpx").setLevel(logging.WARNING)

# ===== 1) 定义 LLM =====

#如果要使用 Google GenAI，请取消注释并配置好 GOOGLE_API_KEY
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-exp",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    api_key=os.environ["GOOGLE_API_KEY"]
)

# 这里使用 langchain 的 ChatOpenAI 初始化 deepseek_llm
deepseek_llm = ChatOpenAI(
    model='deepseek-chat',
    openai_api_key=os.environ["DEEPSEEK_API_KEY"],
    openai_api_base='https://api.deepseek.com',
    max_tokens=8192,
    temperature=0
)


# ===== 2) 定义是否继续对话的 Tool =====
def should_continue_tool_func(user_input):
    prompt = f"""判断用户是否明确表示要结束当前对话。仅回答yes或no，不包含任何其他文字。
yes表示用户不希望结束对话，no表示用户希望结束对话。
请结合用户的实际意图来判断，而不仅仅是根据关键词。
只有当用户非常明确地表示要结束对话时，才回答‘no’，否则回答‘yes’。

User Input: {user_input}

Response:"""
    response = deepseek_llm.invoke(prompt)
    return response.content.strip().lower() == "yes"


should_continue_tool = Tool(
    name="ShouldContinue",
    func=should_continue_tool_func,
    description="Determines whether the conversation should continue based on user input."
)


# ===== 3) 定义对话代理类 =====
class DialogueAgent:
    def __init__(self, model, system_prompt="You are a helpful assistant."):
        self.model = model
        self.system_prompt = system_prompt
        # 初始消息：SystemMessage
        self.messages = [SystemMessage(content=system_prompt)]
        self.dialogue_history = []  # 用于记录对话历史

    @retry(
        retry=retry_if_exception_type(ResourceExhausted),
        wait=wait_exponential(min=1, max=10),
        stop=stop_after_attempt(3),
        reraise=True
    )
    def interact_stream_generator(self, user_input):
        """
        以生成器形式流式输出的交互方法：
        - 前台 (GUI) 可以通过:
            for chunk in agent.interact_stream_generator(user_input):
                # 逐块更新UI
        - 最后一个 yield 之后，对话就完整结束
        """
        # 1) 记录用户输入
        self.messages.append(HumanMessage(content=user_input))
        self.dialogue_history.append(f"**You:** {user_input}")

        try:
            # 2) 调用模型的 stream 方法，得到一个可迭代的响应流
            response_stream = self.model.stream(self.messages)
            full_response = ""

            # 3) 逐块 yield 内容
            for chunk in response_stream:
                text_piece = chunk.content
                full_response += text_piece
                # 把当前块内容 yield 给前端
                yield text_piece

            # 4) 全部完成后，将完整响应写入对话历史
            self.messages.append(AIMessage(content=full_response))
            self.dialogue_history.append(f"**Agent:** {full_response}")

            # 5) 用 None 作为一个“结束标记”，告知前台收尾
            yield None

        except ResourceExhausted as e:
            logging.error(f"ResourceExhausted error: {e}")
            error_message = "API quota exhausted. Please try again later."
            self.dialogue_history.append(f"**Agent:** {error_message}")
            # 同样 yield 这个错误提示
            yield error_message
            yield None

        except Exception as e:
            logging.error(f"Error during interaction: {e}")
            error_message = "An error occurred during the interaction."
            self.dialogue_history.append(f"**Agent:** {error_message}")
            yield error_message
            yield None

    def save_dialogue_to_markdown(self, folder="result"):
        """
        将对话历史保存为 Markdown 文件
        """
        if not os.path.exists(folder):
            os.makedirs(folder)

        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(folder, f"{timestamp}.md")

        with open(filename, "w", encoding="utf-8") as file:
            file.write("# Dialogue History\n\n")
            for entry in self.dialogue_history:
                file.write(f"{entry}\n\n")

        logging.info(f"Dialogue saved to {filename}")

    # 可选：旧的非流式方法（命令行用）
    def interact(self, user_input):
        """
        不需要GUI的场景下，命令行一次性输出的简单示例。
        """
        self.messages.append(HumanMessage(content=user_input))
        self.dialogue_history.append(f"**You:** {user_input}")
        try:
            response_stream = self.model.stream(self.messages)
            print("Agent: ", end="", flush=True)
            full_response = ""
            for chunk in response_stream:
                print(chunk.content, end="", flush=True)
                full_response += chunk.content
            self.messages.append(AIMessage(content=full_response))
            self.dialogue_history.append(f"**Agent:** {full_response}")
            print()
            return full_response
        except ResourceExhausted as e:
            ...
        except Exception as e:
            ...
对这段程序，我要加一个新的tool，在我输入切换到deepseek或者切换到gemini的时候，帮我在llm和deepseek_llm之间切换。

**Agent:** 为了实现你提到的功能，我们需要添加一个新的 `Tool`，用于在 `llm` 和 `deepseek_llm` 之间切换。这个 `Tool` 会监听用户的输入，当用户输入“切换到deepseek”或“切换到gemini”时，动态切换当前使用的模型。

以下是实现这个功能的代码：

### 1. 定义切换模型的 Tool

```python
def switch_model_tool_func(user_input, agent):
    """
    根据用户输入切换模型。
    - 如果用户输入“切换到deepseek”，则切换到 deepseek_llm。
    - 如果用户输入“切换到gemini”，则切换到 llm（Gemini）。
    """
    if "切换到deepseek" in user_input.lower():
        agent.model = deepseek_llm
        return "已切换到 DeepSeek 模型。"
    elif "切换到gemini" in user_input.lower():
        agent.model = llm
        return "已切换到 Gemini 模型。"
    else:
        return "未检测到切换模型的指令。"
```

### 2. 创建 Tool 实例

```python
switch_model_tool = Tool(
    name="SwitchModel",
    func=lambda user_input: switch_model_tool_func(user_input, agent),  # 传入当前的 agent 实例
    description="Switches between DeepSeek and Gemini models based on user input."
)
```

### 3. 修改 `DialogueAgent` 类以支持模型切换

在 `DialogueAgent` 类中，我们需要确保 `model` 属性可以被动态修改。你已经在 `__init__` 中定义了 `self.model`，因此不需要额外修改。

### 4. 在对话中调用 Tool

在对话逻辑中，我们需要在每次用户输入时检查是否需要切换模型。可以在 `interact_stream_generator` 或 `interact` 方法中添加以下逻辑：

```python
def interact_stream_generator(self, user_input):
    # 检查是否需要切换模型
    switch_response = switch_model_tool_func(user_input, self)
    if "已切换到" in switch_response:
        yield switch_response  # 通知用户模型已切换
        return  # 结束当前交互

    # 继续正常的对话逻辑
    self.messages.append(HumanMessage(content=user_input))
    self.dialogue_history.append(f"**You:** {user_input}")

    try:
        response_stream = self.model.stream(self.messages)
        full_response = ""
        for chunk in response_stream:
            text_piece = chunk.content
            full_response += text_piece
            yield text_piece

        self.messages.append(AIMessage(content=full_response))
        self.dialogue_history.append(f"**Agent:** {full_response}")
        yield None

    except ResourceExhausted as e:
        logging.error(f"ResourceExhausted error: {e}")
        error_message = "API quota exhausted. Please try again later."
        self.dialogue_history.append(f"**Agent:** {error_message}")
        yield error_message
        yield None

    except Exception as e:
        logging.error(f"Error during interaction: {e}")
        error_message = "An error occurred during the interaction."
        self.dialogue_history.append(f"**Agent:** {error_message}")
        yield error_message
        yield None
```

### 5. 完整代码示例

以下是整合后的完整代码：

```python
# private_assistant_v2.py
# -*- coding: utf-8 -*-
import os
import logging
import time

from langchain.agents import Tool
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI

from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from google.api_core.exceptions import ResourceExhausted

# 配置日志记录
logging.basicConfig(level=logging.INFO)
logging.getLogger("httpx").setLevel(logging.WARNING)

# ===== 1) 定义 LLM =====

# 如果要使用 Google GenAI，请取消注释并配置好 GOOGLE_API_KEY
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-exp",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    api_key=os.environ["GOOGLE_API_KEY"]
)

# 这里使用 langchain 的 ChatOpenAI 初始化 deepseek_llm
deepseek_llm = ChatOpenAI(
    model='deepseek-chat',
    openai_api_key=os.environ["DEEPSEEK_API_KEY"],
    openai_api_base='https://api.deepseek.com',
    max_tokens=8192,
    temperature=0
)

# ===== 2) 定义是否继续对话的 Tool =====
def should_continue_tool_func(user_input):
    prompt = f"""判断用户是否明确表示要结束当前对话。仅回答yes或no，不包含任何其他文字。
yes表示用户不希望结束对话，no表示用户希望结束对话。
请结合用户的实际意图来判断，而不仅仅是根据关键词。
只有当用户非常明确地表示要结束对话时，才回答‘no’，否则回答‘yes’。

User Input: {user_input}

Response:"""
    response = deepseek_llm.invoke(prompt)
    return response.content.strip().lower() == "yes"

should_continue_tool = Tool(
    name="ShouldContinue",
    func=should_continue_tool_func,
    description="Determines whether the conversation should continue based on user input."
)

# ===== 3) 定义切换模型的 Tool =====
def switch_model_tool_func(user_input, agent):
    """
    根据用户输入切换模型。
    - 如果用户输入“切换到deepseek”，则切换到 deepseek_llm。
    - 如果用户输入“切换到gemini”，则切换到 llm（Gemini）。
    """
    if "切换到deepseek" in user_input.lower():
        agent.model = deepseek_llm
        return "已切换到 DeepSeek 模型。"
    elif "切换到gemini" in user_input.lower():
        agent.model = llm
        return "已切换到 Gemini 模型。"
    else:
        return "未检测到切换模型的指令。"

switch_model_tool = Tool(
    name="SwitchModel",
    func=lambda user_input: switch_model_tool_func(user_input, agent),  # 传入当前的 agent 实例
    description="Switches between DeepSeek and Gemini models based on user input."
)

# ===== 4) 定义对话代理类 =====
class DialogueAgent:
    def __init__(self, model, system_prompt="You are a helpful assistant."):
        self.model = model
        self.system_prompt = system_prompt
        # 初始消息：SystemMessage
        self.messages = [SystemMessage(content=system_prompt)]
        self.dialogue_history = []  # 用于记录对话历史

    @retry(
        retry=retry_if_exception_type(ResourceExhausted),
        wait=wait_exponential(min=1, max=10),
        stop=stop_after_attempt(3),
        reraise=True
    )
    def interact_stream_generator(self, user_input):
        """
        以生成器形式流式输出的交互方法：
        - 前台 (GUI) 可以通过:
            for chunk in agent.interact_stream_generator(user_input):
                # 逐块更新UI
        - 最后一个 yield 之后，对话就完整结束
        """
        # 检查是否需要切换模型
        switch_response = switch_model_tool_func(user_input, self)
        if "已切换到" in switch_response:
            yield switch_response  # 通知用户模型已切换
            return  # 结束当前交互

        # 1) 记录用户输入
        self.messages.append(HumanMessage(content=user_input))
        self.dialogue_history.append(f"**You:** {user_input}")

        try:
            # 2) 调用模型的 stream 方法，得到一个可迭代的响应流
            response_stream = self.model.stream(self.messages)
            full_response = ""

            # 3) 逐块 yield 内容
            for chunk in response_stream:
                text_piece = chunk.content
                full_response += text_piece
                # 把当前块内容 yield 给前端
                yield text_piece

            # 4) 全部完成后，将完整响应写入对话历史
            self.messages.append(AIMessage(content=full_response))
            self.dialogue_history.append(f"**Agent:** {full_response}")

            # 5) 用 None 作为一个“结束标记”，告知前台收尾
            yield None

        except ResourceExhausted as e:
            logging.error(f"ResourceExhausted error: {e}")
            error_message = "API quota exhausted. Please try again later."
            self.dialogue_history.append(f"**Agent:** {error_message}")
            # 同样 yield 这个错误提示
            yield error_message
            yield None

        except Exception as e:
            logging.error(f"Error during interaction: {e}")
            error_message = "An error occurred during the interaction."
            self.dialogue_history.append(f"**Agent:** {error_message}")
            yield error_message
            yield None

    def save_dialogue_to_markdown(self, folder="result"):
        """
        将对话历史保存为 Markdown 文件
        """
        if not os.path.exists(folder):
            os.makedirs(folder)

        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(folder, f"{timestamp}.md")

        with open(filename, "w", encoding="utf-8") as file:
            file.write("# Dialogue History\n\n")
            for entry in self.dialogue_history:
                file.write(f"{entry}\n\n")

        logging.info(f"Dialogue saved to {filename}")

    # 可选：旧的非流式方法（命令行用）
    def interact(self, user_input):
        """
        不需要GUI的场景下，命令行一次性输出的简单示例。
        """
        self.messages.append(HumanMessage(content=user_input))
        self.dialogue_history.append(f"**You:** {user_input}")
        try:
            response_stream = self.model.stream(self.messages)
            print("Agent: ", end="", flush=True)
            full_response = ""
            for chunk in response_stream:
                print(chunk.content, end="", flush=True)
                full_response += chunk.content
            self.messages.append(AIMessage(content=full_response))
            self.dialogue_history.append(f"**Agent:** {full_response}")
            print()
            return full_response
        except ResourceExhausted as e:
            ...
        except Exception as e:
            ...
```

### 6. 使用示例

- 用户输入“切换到deepseek”时，模型会切换到 `deepseek_llm`。
- 用户输入“切换到gemini”时，模型会切换到 `llm`（Gemini）。

### 7. 注意事项

- 确保 `agent` 实例在 `switch_model_tool` 中正确传递。
- 如果需要在多个地方调用 `switch_model_tool`，可以将 `agent` 实例作为参数传递，或者将其作为类属性。

通过这种方式，你可以轻松地在对话中切换模型，而无需重启程序或重新初始化。




**You:** import os
import ast
import json
import sys
import importlib
import importlib.metadata

def extract_ast_features_from_file(file_path, project_root):
    with open(file_path, 'r', encoding='utf-8') as f:
        code = f.read()

    try:
        tree = ast.parse(code)
    except SyntaxError:
        return None

    features = {
        "file_path": file_path,
        "used_functions": [],
        "imports": []
    }

    imported_modules = {}

    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                imported_modules[alias.name] = alias.asname or alias.name
                features["imports"].append({
                    "import_name": alias.name,
                    "from_name": None,
                    "as_name": alias.asname,
                    "source": classify_import_source(alias.name, project_root)
                })
        elif isinstance(node, ast.ImportFrom):
            for alias in node.names:
                imported_modules[f"{node.module}.{alias.name}"] = alias.asname or alias.name
                features["imports"].append({
                    "import_name": alias.name,
                    "from_name": node.module,
                    "as_name": alias.asname,
                    "source": classify_import_source(node.module, project_root)
                })
        elif isinstance(node, ast.Call):
            func_name = ""
            if isinstance(node.func, ast.Name):
                func_name = node.func.id
            elif isinstance(node.func, ast.Attribute):
                if isinstance(node.func.value, ast.Name):
                    module_name = node.func.value.id
                    if module_name in imported_modules:
                        func_name = f"{imported_modules[module_name]}.{node.func.attr}"
                    else:
                        func_name = f"{module_name}.{node.func.attr}"
                elif isinstance(node.func.value,ast.Call):
                    #处理a().b()的情况，递归调用
                    func_name_prefix=extract_function_name_from_node(node.func.value,imported_modules)
                    if func_name_prefix:
                        func_name = f"{func_name_prefix}.{node.func.attr}"
                else:
                    pass
            elif isinstance(node.func, ast.Subscript):
                #处理a[0]()的情况
                pass
            if func_name:
                features["used_functions"].append(func_name)

    return features
def extract_function_name_from_node(node,imported_modules):
    func_name = ""
    if isinstance(node, ast.Name):
        func_name = node.id
    elif isinstance(node, ast.Attribute):
        if isinstance(node.func.value, ast.Name):
            module_name = node.func.value.id
            if module_name in imported_modules:
                func_name = f"{imported_modules[module_name]}.{node.func.attr}"
            else:
                func_name = f"{module_name}.{node.func.attr}"
        elif isinstance(node.func.value,ast.Call):
            func_name_prefix=extract_function_name_from_node(node.func.value,imported_modules)
            if func_name_prefix:
                func_name = f"{func_name_prefix}.{node.func.attr}"
        else:
            pass
    return func_name

def classify_import_source(module_name, project_root):
    if module_name in sys.builtin_module_names:
        return "内置模块"

    try:
        installed_packages = {pkg.metadata['Name'].lower() for pkg in importlib.metadata.distributions()}
        if module_name.lower() in installed_packages:
            return "第三方库"
    except Exception as e:
        print(f"Error checking installed packages: {e}")
        return "未知模块"

    local_path = os.path.join(project_root, module_name.replace('.', os.sep) + '.py')
    if os.path.exists(local_path):
        return f"本地文件: {local_path}"

    return "未知模块"

def traverse_directory_and_extract_features(directory):
    ast_features = []

    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith(".py"):
                file_path = os.path.join(root, file)
                features = extract_ast_features_from_file(file_path, directory)
                if features:
                    ast_features.append(features)

    return ast_features

def save_features_to_json(features, output_path):
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(features, f, indent=4, ensure_ascii=False)

if __name__ == "__main__":
    project_directory = "Python"  # 替换为你的项目路径
    output_file = "ast_features.json"

    print(f"正在解析项目目录：{project_directory}")
    features = traverse_directory_and_extract_features(project_directory)
    print(f"解析完成，共提取 {len(features)} 个文件的AST特征。")

    save_features_to_json(features, output_file)
    print(f"AST特征已保存至：{output_file}")对这段程序，对于每个py文件，以它的每个函数为界限分析他会使用到的库，而不是整个py文件会使用到的库

**Agent:** 要实现以每个函数为界限分析其使用的库，我们需要对代码进行更细粒度的分析。具体来说，我们需要遍历每个函数的 AST 节点，并记录该函数内部使用的库和函数调用。

以下是修改后的代码，实现了以函数为单位分析其使用的库：

### 修改后的代码

```python
import os
import ast
import json
import sys
import importlib
import importlib.metadata

def extract_ast_features_from_file(file_path, project_root):
    with open(file_path, 'r', encoding='utf-8') as f:
        code = f.read()

    try:
        tree = ast.parse(code)
    except SyntaxError:
        return None

    features = {
        "file_path": file_path,
        "functions": []
    }

    imported_modules = {}

    # 先提取全局的 import 信息
    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                imported_modules[alias.name] = alias.asname or alias.name
        elif isinstance(node, ast.ImportFrom):
            for alias in node.names:
                imported_modules[f"{node.module}.{alias.name}"] = alias.asname or alias.name

    # 遍历每个函数定义
    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            function_features = {
                "function_name": node.name,
                "used_functions": [],
                "imports": []
            }

            # 遍历函数体内的节点
            for func_node in ast.walk(node):
                if isinstance(func_node, ast.Call):
                    func_name = extract_function_name_from_node(func_node.func, imported_modules)
                    if func_name:
                        function_features["used_functions"].append(func_name)

            # 记录该函数使用的库
            for import_name, as_name in imported_modules.items():
                for used_func in function_features["used_functions"]:
                    if used_func.startswith(import_name):
                        function_features["imports"].append({
                            "import_name": import_name,
                            "as_name": as_name,
                            "source": classify_import_source(import_name, project_root)
                        })

            features["functions"].append(function_features)

    return features

def extract_function_name_from_node(node, imported_modules):
    func_name = ""
    if isinstance(node, ast.Name):
        func_name = node.id
    elif isinstance(node, ast.Attribute):
        if isinstance(node.value, ast.Name):
            module_name = node.value.id
            if module_name in imported_modules:
                func_name = f"{imported_modules[module_name]}.{node.attr}"
            else:
                func_name = f"{module_name}.{node.attr}"
        elif isinstance(node.value, ast.Call):
            func_name_prefix = extract_function_name_from_node(node.value, imported_modules)
            if func_name_prefix:
                func_name = f"{func_name_prefix}.{node.attr}"
    return func_name

def classify_import_source(module_name, project_root):
    if module_name in sys.builtin_module_names:
        return "内置模块"

    try:
        installed_packages = {pkg.metadata['Name'].lower() for pkg in importlib.metadata.distributions()}
        if module_name.lower() in installed_packages:
            return "第三方库"
    except Exception as e:
        print(f"Error checking installed packages: {e}")
        return "未知模块"

    local_path = os.path.join(project_root, module_name.replace('.', os.sep) + '.py')
    if os.path.exists(local_path):
        return f"本地文件: {local_path}"

    return "未知模块"

def traverse_directory_and_extract_features(directory):
    ast_features = []

    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith(".py"):
                file_path = os.path.join(root, file)
                features = extract_ast_features_from_file(file_path, directory)
                if features:
                    ast_features.append(features)

    return ast_features

def save_features_to_json(features, output_path):
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(features, f, indent=4, ensure_ascii=False)

if __name__ == "__main__":
    project_directory = "Python"  # 替换为你的项目路径
    output_file = "ast_features.json"

    print(f"正在解析项目目录：{project_directory}")
    features = traverse_directory_and_extract_features(project_directory)
    print(f"解析完成，共提取 {len(features)} 个文件的AST特征。")

    save_features_to_json(features, output_file)
    print(f"AST特征已保存至：{output_file}")
```

### 主要修改点

1. **函数级别的分析**：
   - 在 `extract_ast_features_from_file` 函数中，我们遍历每个 `ast.FunctionDef` 节点，提取函数名和函数体内的调用信息。
   - 每个函数的 `used_functions` 和 `imports` 信息被单独记录。

2. **函数调用解析**：
   - `extract_function_name_from_node` 函数用于解析函数调用节点，提取完整的函数名（包括模块名和函数名）。

3. **库的使用分析**：
   - 在函数级别，我们检查每个函数调用的函数是否依赖于某个导入的库，并将相关信息记录在 `imports` 中。

4. **输出结构**：
   - 每个文件的输出结构包含多个函数的信息，每个函数的信息包括其使用的库和调用的函数。

### 输出示例

假设有一个 Python 文件 `example.py`，内容如下：

```python
import os
import math

def func1():
    print(os.getcwd())
    return math.sqrt(16)

def func2():
    return os.path.join("a", "b")
```

运行程序后，输出的 JSON 文件内容可能如下：

```json
[
    {
        "file_path": "example.py",
        "functions": [
            {
                "function_name": "func1",
                "used_functions": ["os.getcwd", "math.sqrt"],
                "imports": [
                    {
                        "import_name": "os",
                        "as_name": "os",
                        "source": "内置模块"
                    },
                    {
                        "import_name": "math",
                        "as_name": "math",
                        "source": "内置模块"
                    }
                ]
            },
            {
                "function_name": "func2",
                "used_functions": ["os.path.join"],
                "imports": [
                    {
                        "import_name": "os",
                        "as_name": "os",
                        "source": "内置模块"
                    }
                ]
            }
        ]
    }
]
```

### 总结

通过这种方式，你可以以函数为单位分析其使用的库和函数调用，从而更精确地了解代码的依赖关系。这对于代码优化、依赖管理和重构非常有帮助。



**You:** 然后把这个代码也修正成可以读取上述json结果转换成html的版本：import json
import networkx as nx
import matplotlib.pyplot as plt
from jinja2 import Environment, FileSystemLoader
from pyvis.network import Network


def build_dependency_graph(ast_features):
    """构建跨文件依赖图。"""
    graph = nx.DiGraph()

    for feature in ast_features:
        file_path = feature["file_path"]
        graph.add_node(file_path)

        for import_data in feature["imports"]:
            import_name = import_data["import_name"]
            from_name = import_data["from_name"]

            # 构建依赖边的名称，优先使用from_name
            dependency_name = from_name if from_name else import_name

            if dependency_name:  # 避免None值导致错误
                graph.add_edge(file_path, dependency_name)

    return graph


# ... (find_related_files, selective_retrieval_with_imports, print_dependency_graph 函数可以根据需要保留或删除，本次修改不涉及)

def draw_dependency_graph(graph, output_file="dependency_graph.png"):
    """绘制依赖图并保存为图像文件。"""
    plt.figure(figsize=(12, 8))
    nx.draw(graph, with_labels=True, node_size=2000, node_color="lightblue", font_size=10, font_weight="bold",
            arrowsize=20)
    plt.title("Cross-File Dependency Graph")
    plt.savefig(output_file)
    print(f"依赖图已保存为 {output_file}")
    plt.show()


def generate_interactive_graph(graph, output_file="dependency_graph.html"):
    net = Network(notebook=False, directed=True)

    for node in graph.nodes:
        net.add_node(node, label=node)

    for edge in graph.edges:
        net.add_edge(edge[0], edge[1])

    # 指定模板路径 (根据你的实际路径修改)
    template_path = "C:/Users/J100052060/PycharmProjects/pythonProject1/venv/lib/site-packages/pyvis/templates"  # 请修改此路径
    env = Environment(loader=FileSystemLoader(template_path))
    net.template = env.get_template("template.html")

    net.show(output_file)
    print(f"交互式依赖图已保存为 {output_file}")


if __name__ == "__main__":
    with open("ast_features.json", 'r', encoding="utf-8") as ast:  # 添加encoding
        ast_data = json.load(ast)
    ast_graph = build_dependency_graph(ast_data)

    draw_dependency_graph(ast_graph)
    generate_interactive_graph(ast_graph)

**Agent:** 为了将 JSON 结果转换为 HTML 并生成交互式依赖图，我们需要对代码进行一些调整。以下是修改后的代码，它将读取 JSON 文件并生成一个 HTML 文件，展示每个函数及其使用的库和函数调用。

### 修改后的代码

```python
import json
import networkx as nx
import matplotlib.pyplot as plt
from jinja2 import Environment, FileSystemLoader
from pyvis.network import Network

def build_dependency_graph(ast_features):
    """构建跨文件依赖图。"""
    graph = nx.DiGraph()

    for feature in ast_features:
        file_path = feature["file_path"]
        graph.add_node(file_path, label=file_path, group="file")

        for func in feature["functions"]:
            func_name = f"{file_path}:{func['function_name']}"
            graph.add_node(func_name, label=func['function_name'], group="function")
            graph.add_edge(file_path, func_name)

            for used_func in func["used_functions"]:
                graph.add_node(used_func, label=used_func, group="function_call")
                graph.add_edge(func_name, used_func)

            for import_data in func["imports"]:
                import_name = import_data["import_name"]
                graph.add_node(import_name, label=import_name, group="import")
                graph.add_edge(func_name, import_name)

    return graph

def draw_dependency_graph(graph, output_file="dependency_graph.png"):
    """绘制依赖图并保存为图像文件。"""
    plt.figure(figsize=(12, 8))
    pos = nx.spring_layout(graph)
    nx.draw(graph, pos, with_labels=True, node_size=2000, node_color="lightblue", font_size=10, font_weight="bold", arrowsize=20)
    plt.title("Cross-File Dependency Graph")
    plt.savefig(output_file)
    print(f"依赖图已保存为 {output_file}")
    plt.show()

def generate_interactive_graph(graph, output_file="dependency_graph.html"):
    """生成交互式依赖图并保存为 HTML 文件。"""
    net = Network(notebook=False, directed=True, height="750px", width="100%", bgcolor="#222222", font_color="white")

    # 添加节点和边
    for node in graph.nodes:
        group = graph.nodes[node].get("group", "default")
        label = graph.nodes[node].get("label", node)
        net.add_node(node, label=label, group=group)

    for edge in graph.edges:
        net.add_edge(edge[0], edge[1])

    # 指定模板路径 (根据你的实际路径修改)
    template_path = "C:/Users/J100052060/PycharmProjects/pythonProject1/venv/lib/site-packages/pyvis/templates"  # 请修改此路径
    env = Environment(loader=FileSystemLoader(template_path))
    net.template = env.get_template("template.html")

    net.show(output_file)
    print(f"交互式依赖图已保存为 {output_file}")

if __name__ == "__main__":
    with open("ast_features.json", 'r', encoding="utf-8") as ast:  # 添加encoding
        ast_data = json.load(ast)
    ast_graph = build_dependency_graph(ast_data)

    draw_dependency_graph(ast_graph)
    generate_interactive_graph(ast_graph)
```

### 主要修改点

1. **节点分组**：
   - 我们将节点分为三类：`file`（文件）、`function`（函数）、`function_call`（函数调用）和 `import`（导入的库）。
   - 每个节点的 `group` 属性用于在 HTML 中区分不同类型的节点。

2. **节点标签**：
   - 每个节点的 `label` 属性用于在 HTML 中显示节点的名称。

3. **交互式图生成**：
   - 使用 `pyvis` 库生成交互式依赖图，并将其保存为 HTML 文件。
   - 通过 `group` 属性，不同类型的节点在 HTML 中会以不同的颜色显示。

4. **模板路径**：
   - 你需要根据实际路径修改 `template_path`，确保 `pyvis` 的模板文件能够正确加载。

### 输出示例

假设 `ast_features.json` 文件内容如下：

```json
[
    {
        "file_path": "example.py",
        "functions": [
            {
                "function_name": "func1",
                "used_functions": ["os.getcwd", "math.sqrt"],
                "imports": [
                    {
                        "import_name": "os",
                        "as_name": "os",
                        "source": "内置模块"
                    },
                    {
                        "import_name": "math",
                        "as_name": "math",
                        "source": "内置模块"
                    }
                ]
            },
            {
                "function_name": "func2",
                "used_functions": ["os.path.join"],
                "imports": [
                    {
                        "import_name": "os",
                        "as_name": "os",
                        "source": "内置模块"
                    }
                ]
            }
        ]
    }
]
```

生成的 HTML 文件将展示以下内容：

- **文件节点**：`example.py`
- **函数节点**：`func1` 和 `func2`
- **函数调用节点**：`os.getcwd`、`math.sqrt`、`os.path.join`
- **导入库节点**：`os`、`math`

### 总结

通过这种方式，你可以将 JSON 结果转换为交互式 HTML 依赖图，方便查看每个函数及其使用的库和函数调用。这对于代码分析、依赖管理和重构非常有帮助。

